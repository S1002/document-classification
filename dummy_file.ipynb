{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a147ebe3-4fee-400a-8047-83d6a48cc3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"C:\\ML Training Docs\\New folder\\New folder (2)\\new\\3rdparties\\7991249.txt\", 'r',encoding='utf8') as file:\n",
    "    data = file.read().replace('\\n', '')\n",
    "    file.close()\n",
    "    #print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5e11166-249f-4761-b568-8b401d483936",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=[data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2827023f-5927-4a22-b424-7b31d9cae2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "documents_test = []\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "stop_words=set(stopwords.words('english'))\n",
    "stemmer = WordNetLemmatizer()\n",
    "\n",
    "for sen in range(0, len(data)):\n",
    "    \n",
    "    #Remove \\n from text\n",
    "    document_test = re.sub(r'\\\\n', ' ', str(data[sen]))\n",
    "    \n",
    "    # remove \\t from text\n",
    "    document_test = re.sub(r'\\\\t', ' ', document_test)\n",
    "    \n",
    "     # Remove \\\\ from the text\n",
    "    document_test = re.sub(r'\\\\', ' ', document_test)\n",
    "    \n",
    "     # Removing prefixed 'b'\n",
    "    document_test = re.sub(r'^b\\s+', '', document_test)\n",
    "    \n",
    "    \n",
    "    #Remove special character\n",
    "    document_test = re.sub(r\"[^a-zA-Z0-9]+\", ' ', document_test)\n",
    "    \n",
    "   \n",
    "\n",
    "    \n",
    "    # Remove one char joins with 2 digit number\n",
    "    document_test= re.sub(r'[A-Za-z]{1}[0-9]{2}', ' ', document_test)\n",
    "    #Remove 1 digit number joins with 2 char\n",
    "    document_test = re.sub(r'[0-9]{1}[A-Za-z]{2}',' ',document_test)\n",
    "     #Remove one char in between two numbers\n",
    "    document_test = re.sub(r'[0-9]{1}[A-Za-z]{1}[0-9]{1}',' ',document_test)\n",
    "    #Remove one number in between two char\n",
    "    document_test = re.sub(r'[A-Za-z]{1}[0-9]{1}[A-Za-z]{1}',' ',document_test)\n",
    "    \n",
    "    # Remove two char joins with 2 digit number\n",
    "    document_test= re.sub(r'[A-Za-z]{2}[0-9]{2}', ' ', document_test)\n",
    "    \n",
    "    # Remove two char joins with 1 digit number\n",
    "    document_test= re.sub(r'[A-Za-z]{2}[0-9]{1}', ' ', document_test)\n",
    "    \n",
    "   \n",
    "    # Remove double digit number\n",
    "    document_test=re.sub('(\\\\b[0-9][0-9] \\\\b|\\\\b [0-9][0-9]\\\\b)', ' ', document_test).strip()\n",
    "    #Remove single character\n",
    "    document_test=re.sub('(\\\\b[A-Za-z] \\\\b|\\\\b [A-Za-z]\\\\b)', ' ', document_test).strip()\n",
    "    # Remove single digit number\n",
    "    document_test=re.sub('(\\\\b[0-9] \\\\b|\\\\b [0-9]\\\\b)', ' ', document_test).strip()\n",
    "\n",
    "    # Substituting multiple spaces with single space\n",
    "    document_test = re.sub(r' +', ' ', document_test)\n",
    "\n",
    "    # Converting to Lowercase\n",
    "    document_test = document_test.lower()\n",
    "    \n",
    "    # Lemmatization\n",
    "    document_test = document_test.split()\n",
    "\n",
    "    document_test = [stemmer.lemmatize(word) for word in document_test]\n",
    "    document_test = ' '.join(document_test)\n",
    "#     document = ' '.join(e for e in document if e.isalnum())\n",
    "    document_test = ' '.join([word for word in document_test.split(' ') if word not in stop_words])\n",
    "    document_test = ' '.join([w for w in document_test.split() if len(w)>1])\n",
    "    \n",
    "    \n",
    "    \n",
    "    documents_test.append(document_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93595151-c939-4280-9e86-62869b4fe02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_list_test = documents_test\n",
    "from nltk.corpus import stopwords\n",
    "stop_words=set(stopwords.words('english'))\n",
    "\n",
    "clean_document_test = [' '.join([b for b in a.split() if b not in stop_words]) for a in doc_list_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aced77ad-6c91-469d-9074-46069fa51b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "count_vectorizer_saved=joblib.load(open(r'C:\\ML Training Docs\\New folder\\pickle file\\count_vectorizer_cv.sav','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aff4828b-f51e-4614-b37a-264ae53cdbaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_features=count_vectorizer_saved.transform(clean_document_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f0556d92-77fa-44ec-9ada-947bd4fb4811",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_saved=joblib.load(open(r'C:\\ML Training Docs\\New folder\\pickle file\\term_freq_inv_df.sav','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4ec3904-039b-4ce7-9978-3fcf17fb75a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_features_tfidf=tfidf_saved.transform(test_data_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3ac8470-df36-4c6a-9be7-2d0a4fc454d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_pickled_model=joblib.load(open(r'C:\\ML Training Docs\\New folder\\pickle file\\light_gbm.sav','rb'))\n",
    "lgbm_pickled_model.predict(test_data_features_tfidf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
