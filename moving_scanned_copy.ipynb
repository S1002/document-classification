{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c833e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be27b703",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pdf_searchable_pages(fname):\n",
    "    \n",
    "    # pip install pdfminer\n",
    "    from pdfminer.pdfpage import PDFPage\n",
    "    source_dir = 'C:/ML Training Docs/New folder/data/Moving scanned copy/.PDF/'\n",
    "    target_dir = 'C:/ML Training Docs/New folder/data/Moving scanned copy/scanned_copy/'\n",
    "    searchable_pages = []\n",
    "    non_searchable_pages = []\n",
    "    page_num = 0\n",
    "    with open(fname, 'rb') as infile:\n",
    "\n",
    "        for page in PDFPage.get_pages(infile):\n",
    "            page_num += 1\n",
    "            if 'Font' in page.resources.keys():\n",
    "                searchable_pages.append(page_num)\n",
    "            else:\n",
    "                non_searchable_pages.append(page_num)\n",
    "    if page_num > 0:\n",
    "        if len(searchable_pages) == 0:\n",
    "            shutil.move(os.path.join(source_dir, file_name), target_dir)\n",
    "            print(f\"Document '{fname}' has {page_num} page(s). \"\n",
    "                  f\"Complete document is non-searchable\")\n",
    "        elif len(non_searchable_pages) == 0:\n",
    "            print(f\"Document '{fname}' has {page_num} page(s). \"\n",
    "                  f\"Complete document is searchable\")\n",
    "        else:\n",
    "#             print(f\"searchable_pages : {searchable_pages}\")\n",
    "#             if non_searchable_pages != None:\n",
    "                \n",
    "#                 shutil.move(os.path.join(source_dir, file_name), target_dir)\n",
    "            \n",
    "                print(f\"non_searchable_pages : {non_searchable_pages}\")\n",
    "    else:\n",
    "        print(f\"Not a valid document\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5088e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1580029.pdf\n",
      "Document 'C:/ML Training Docs/New folder/data/Moving scanned copy/.PDF/1580029.pdf' has 2 page(s). Complete document is non-searchable\n",
      "1580047.pdf\n",
      "Document 'C:/ML Training Docs/New folder/data/Moving scanned copy/.PDF/1580047.pdf' has 1 page(s). Complete document is non-searchable\n",
      "1580049.pdf\n",
      "Document 'C:/ML Training Docs/New folder/data/Moving scanned copy/.PDF/1580049.pdf' has 11 page(s). Complete document is non-searchable\n",
      "1580050.pdf\n",
      "Document 'C:/ML Training Docs/New folder/data/Moving scanned copy/.PDF/1580050.pdf' has 20 page(s). Complete document is searchable\n",
      "1580052.pdf\n",
      "Document 'C:/ML Training Docs/New folder/data/Moving scanned copy/.PDF/1580052.pdf' has 21 page(s). Complete document is non-searchable\n",
      "1580053.pdf\n",
      "Document 'C:/ML Training Docs/New folder/data/Moving scanned copy/.PDF/1580053.pdf' has 21 page(s). Complete document is non-searchable\n",
      "1880052.pdf\n",
      "non_searchable_pages : [30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120]\n",
      "2100044.pdf\n",
      "Document 'C:/ML Training Docs/New folder/data/Moving scanned copy/.PDF/2100044.pdf' has 1 page(s). Complete document is searchable\n",
      "2350039.pdf\n",
      "Document 'C:/ML Training Docs/New folder/data/Moving scanned copy/.PDF/2350039.pdf' has 1 page(s). Complete document is non-searchable\n",
      "2490021.pdf\n",
      "Document 'C:/ML Training Docs/New folder/data/Moving scanned copy/.PDF/2490021.pdf' has 7 page(s). Complete document is non-searchable\n",
      "260023.pdf\n",
      "Document 'C:/ML Training Docs/New folder/data/Moving scanned copy/.PDF/260023.pdf' has 6 page(s). Complete document is non-searchable\n",
      "2720035.pdf\n",
      "Document 'C:/ML Training Docs/New folder/data/Moving scanned copy/.PDF/2720035.pdf' has 7 page(s). Complete document is searchable\n",
      "2970052.pdf\n",
      "Document 'C:/ML Training Docs/New folder/data/Moving scanned copy/.PDF/2970052.pdf' has 2 page(s). Complete document is non-searchable\n",
      "30047.pdf\n",
      "Document 'C:/ML Training Docs/New folder/data/Moving scanned copy/.PDF/30047.pdf' has 28 page(s). Complete document is non-searchable\n",
      "3010032.pdf\n",
      "Document 'C:/ML Training Docs/New folder/data/Moving scanned copy/.PDF/3010032.pdf' has 4 page(s). Complete document is non-searchable\n",
      "3030026.pdf\n",
      "Document 'C:/ML Training Docs/New folder/data/Moving scanned copy/.PDF/3030026.pdf' has 4 page(s). Complete document is searchable\n",
      "3120003.pdf\n",
      "Document 'C:/ML Training Docs/New folder/data/Moving scanned copy/.PDF/3120003.pdf' has 3 page(s). Complete document is searchable\n",
      "3130027.pdf\n",
      "Document 'C:/ML Training Docs/New folder/data/Moving scanned copy/.PDF/3130027.pdf' has 2 page(s). Complete document is non-searchable\n",
      "3210005.pdf\n",
      "Document 'C:/ML Training Docs/New folder/data/Moving scanned copy/.PDF/3210005.pdf' has 4 page(s). Complete document is non-searchable\n",
      "3230044.pdf\n",
      "Document 'C:/ML Training Docs/New folder/data/Moving scanned copy/.PDF/3230044.pdf' has 22 page(s). Complete document is searchable\n",
      "3330041.pdf\n",
      "Document 'C:/ML Training Docs/New folder/data/Moving scanned copy/.PDF/3330041.pdf' has 1 page(s). Complete document is non-searchable\n",
      "3410032.pdf\n",
      "Document 'C:/ML Training Docs/New folder/data/Moving scanned copy/.PDF/3410032.pdf' has 3 page(s). Complete document is searchable\n",
      "3430015.pdf\n",
      "Document 'C:/ML Training Docs/New folder/data/Moving scanned copy/.PDF/3430015.pdf' has 1 page(s). Complete document is non-searchable\n",
      "3840002.pdf\n",
      "Document 'C:/ML Training Docs/New folder/data/Moving scanned copy/.PDF/3840002.pdf' has 2 page(s). Complete document is non-searchable\n",
      "3850011.pdf\n",
      "Document 'C:/ML Training Docs/New folder/data/Moving scanned copy/.PDF/3850011.pdf' has 16 page(s). Complete document is searchable\n",
      "3870024.pdf\n",
      "Document 'C:/ML Training Docs/New folder/data/Moving scanned copy/.PDF/3870024.pdf' has 13 page(s). Complete document is non-searchable\n",
      "3880043.pdf\n",
      "Document 'C:/ML Training Docs/New folder/data/Moving scanned copy/.PDF/3880043.pdf' has 58 page(s). Complete document is non-searchable\n",
      "4710012.pdf\n",
      "Document 'C:/ML Training Docs/New folder/data/Moving scanned copy/.PDF/4710012.pdf' has 1 page(s). Complete document is searchable\n",
      "4890005.pdf\n",
      "Document 'C:/ML Training Docs/New folder/data/Moving scanned copy/.PDF/4890005.pdf' has 5 page(s). Complete document is searchable\n",
      "4900051.pdf\n",
      "Document 'C:/ML Training Docs/New folder/data/Moving scanned copy/.PDF/4900051.pdf' has 4 page(s). Complete document is searchable\n",
      "5040026.pdf\n",
      "non_searchable_pages : [4]\n",
      "5210033.pdf\n",
      "Document 'C:/ML Training Docs/New folder/data/Moving scanned copy/.PDF/5210033.pdf' has 5 page(s). Complete document is searchable\n",
      "5260048.pdf\n",
      "Document 'C:/ML Training Docs/New folder/data/Moving scanned copy/.PDF/5260048.pdf' has 9 page(s). Complete document is searchable\n",
      "5510027.pdf\n",
      "Document 'C:/ML Training Docs/New folder/data/Moving scanned copy/.PDF/5510027.pdf' has 7 page(s). Complete document is searchable\n",
      "5600047.pdf\n",
      "Document 'C:/ML Training Docs/New folder/data/Moving scanned copy/.PDF/5600047.pdf' has 2 page(s). Complete document is non-searchable\n",
      "570047.pdf\n",
      "Document 'C:/ML Training Docs/New folder/data/Moving scanned copy/.PDF/570047.pdf' has 14 page(s). Complete document is non-searchable\n",
      "5740046.pdf\n",
      "non_searchable_pages : [4, 12]\n",
      "5940044.pdf\n",
      "Document 'C:/ML Training Docs/New folder/data/Moving scanned copy/.PDF/5940044.pdf' has 3 page(s). Complete document is searchable\n",
      "6000006.pdf\n",
      "Document 'C:/ML Training Docs/New folder/data/Moving scanned copy/.PDF/6000006.pdf' has 6 page(s). Complete document is searchable\n",
      "6170021.pdf\n",
      "Document 'C:/ML Training Docs/New folder/data/Moving scanned copy/.PDF/6170021.pdf' has 5 page(s). Complete document is searchable\n",
      "6190026.pdf\n",
      "Document 'C:/ML Training Docs/New folder/data/Moving scanned copy/.PDF/6190026.pdf' has 15 page(s). Complete document is searchable\n",
      "6190038.pdf\n",
      "Document 'C:/ML Training Docs/New folder/data/Moving scanned copy/.PDF/6190038.pdf' has 1 page(s). Complete document is searchable\n",
      "6390045.pdf\n",
      "Document 'C:/ML Training Docs/New folder/data/Moving scanned copy/.PDF/6390045.pdf' has 8 page(s). Complete document is non-searchable\n",
      "650038.pdf\n",
      "Document 'C:/ML Training Docs/New folder/data/Moving scanned copy/.PDF/650038.pdf' has 7 page(s). Complete document is non-searchable\n",
      "6540040.pdf\n",
      "Document 'C:/ML Training Docs/New folder/data/Moving scanned copy/.PDF/6540040.pdf' has 6 page(s). Complete document is non-searchable\n",
      "6550046.pdf\n",
      "Document 'C:/ML Training Docs/New folder/data/Moving scanned copy/.PDF/6550046.pdf' has 7 page(s). Complete document is searchable\n",
      "660007.pdf\n",
      "Document 'C:/ML Training Docs/New folder/data/Moving scanned copy/.PDF/660007.pdf' has 68 page(s). Complete document is searchable\n",
      "660010.pdf\n",
      "Document 'C:/ML Training Docs/New folder/data/Moving scanned copy/.PDF/660010.pdf' has 68 page(s). Complete document is searchable\n",
      "660012.pdf\n",
      "Document 'C:/ML Training Docs/New folder/data/Moving scanned copy/.PDF/660012.pdf' has 4 page(s). Complete document is searchable\n",
      "660029.pdf\n",
      "Document 'C:/ML Training Docs/New folder/data/Moving scanned copy/.PDF/660029.pdf' has 2 page(s). Complete document is searchable\n",
      "660044.pdf\n",
      "Document 'C:/ML Training Docs/New folder/data/Moving scanned copy/.PDF/660044.pdf' has 3 page(s). Complete document is non-searchable\n",
      "6620048.pdf\n",
      "Document 'C:/ML Training Docs/New folder/data/Moving scanned copy/.PDF/6620048.pdf' has 19 page(s). Complete document is non-searchable\n",
      "6850029.pdf\n",
      "Document 'C:/ML Training Docs/New folder/data/Moving scanned copy/.PDF/6850029.pdf' has 15 page(s). Complete document is searchable\n",
      "6890035.pdf\n",
      "Document 'C:/ML Training Docs/New folder/data/Moving scanned copy/.PDF/6890035.pdf' has 1 page(s). Complete document is searchable\n",
      "7150029.pdf\n",
      "non_searchable_pages : [6, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91]\n",
      "7470026.pdf\n",
      "Document 'C:/ML Training Docs/New folder/data/Moving scanned copy/.PDF/7470026.pdf' has 1 page(s). Complete document is searchable\n",
      "7610036.pdf\n",
      "non_searchable_pages : [2, 4, 5, 6, 7, 8, 9]\n",
      "7640001.pdf\n",
      "Document 'C:/ML Training Docs/New folder/data/Moving scanned copy/.PDF/7640001.pdf' has 1 page(s). Complete document is searchable\n",
      "7650011.pdf\n",
      "Document 'C:/ML Training Docs/New folder/data/Moving scanned copy/.PDF/7650011.pdf' has 2 page(s). Complete document is non-searchable\n",
      "7690026.pdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 'C:/ML Training Docs/New folder/data/Moving scanned copy/.PDF/7690026.pdf' has 6 page(s). Complete document is searchable\n",
      "7740029.pdf\n",
      "Document 'C:/ML Training Docs/New folder/data/Moving scanned copy/.PDF/7740029.pdf' has 6 page(s). Complete document is searchable\n",
      "7880002.pdf\n",
      "Document 'C:/ML Training Docs/New folder/data/Moving scanned copy/.PDF/7880002.pdf' has 2 page(s). Complete document is non-searchable\n",
      "7880032.pdf\n",
      "Document 'C:/ML Training Docs/New folder/data/Moving scanned copy/.PDF/7880032.pdf' has 98 page(s). Complete document is searchable\n",
      "7890049.pdf\n"
     ]
    },
    {
     "ename": "PDFTextExtractionNotAllowed",
     "evalue": "Text extraction is not allowed: <_io.BufferedReader name='C:/ML Training Docs/New folder/data/Moving scanned copy/.PDF/7890049.pdf'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPDFTextExtractionNotAllowed\u001b[0m               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-221008db3973>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mfile_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msource_dir\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mget_pdf_searchable_pages\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-1-c4cf72eb4743>\u001b[0m in \u001b[0;36mget_pdf_searchable_pages\u001b[1;34m(fname)\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0minfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mpage\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mPDFPage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_pages\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m             \u001b[0mpage_num\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;34m'Font'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresources\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pdfminer\\pdfpage.py\u001b[0m in \u001b[0;36mget_pages\u001b[1;34m(klass, fp, pagenos, maxpages, password, caching, check_extractable)\u001b[0m\n\u001b[0;32m    123\u001b[0m         \u001b[1;31m# Check if the document allows text extraction. If not, abort.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcheck_extractable\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mdoc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_extractable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 125\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mPDFTextExtractionNotAllowed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Text extraction is not allowed: %r'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    126\u001b[0m         \u001b[1;31m# Process each page contained in the document.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mpageno\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpage\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mklass\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_pages\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPDFTextExtractionNotAllowed\u001b[0m: Text extraction is not allowed: <_io.BufferedReader name='C:/ML Training Docs/New folder/data/Moving scanned copy/.PDF/7890049.pdf'>"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "source_dir = os.path.join('C:/ML Training Docs/New folder/data/Moving scanned copy/.PDF/')\n",
    "\n",
    "for filename in os.listdir(source_dir):\n",
    "    file, extension = os.path.splitext(filename)\n",
    "    if filename[-3:] == 'pdf':\n",
    "        print(filename)\n",
    "        \n",
    "        file_name = source_dir+filename\n",
    "        get_pdf_searchable_pages(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06fad97e",
   "metadata": {},
   "source": [
    "# Docuent classification with splitted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f463e360",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "#nltk.download('stopwords')\n",
    "import pickle\n",
    "#from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c67f1fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def explode(df, lst_cols, fill_value='', preserve_index=False):\n",
    "    # make sure `lst_cols` is list-alike\n",
    "    if (lst_cols is not None\n",
    "        and len(lst_cols) > 0\n",
    "        and not isinstance(lst_cols, (list, tuple, np.ndarray, pd.Series))):\n",
    "        lst_cols = [lst_cols]\n",
    "    # all columns except `lst_cols`\n",
    "    idx_cols = df.columns.difference(lst_cols)\n",
    "    # calculate lengths of lists\n",
    "    lens = df[lst_cols[0]].str.len()\n",
    "    # preserve original index values    \n",
    "    idx = np.repeat(df.index.values, lens)\n",
    "    # create \"exploded\" DF\n",
    "    res = (pd.DataFrame({\n",
    "                col:np.repeat(df[col].values, lens)\n",
    "                for col in idx_cols},\n",
    "                index=idx)\n",
    "             .assign(**{col:np.concatenate(df.loc[lens>0, col].values)\n",
    "                            for col in lst_cols}))\n",
    "    # append those rows that have empty lists\n",
    "    if (lens == 0).any():\n",
    "        # at least one list in cells is empty\n",
    "        res = (res.append(df.loc[lens==0, idx_cols], sort=False)\n",
    "                  .fillna(fill_value))\n",
    "    # revert the original index order\n",
    "    res = res.sort_index()\n",
    "    # reset index if requested\n",
    "    if not preserve_index:        \n",
    "        res = res.reset_index(drop=True)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7309f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_files\n",
    "my_data=load_files(r'C:\\ML Training Docs\\New folder\\split\\Train')\n",
    "X,y = my_data.data, my_data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ea4eb44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filenames</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:\\ML Training Docs\\New folder\\split\\Train\\MDU...</td>\n",
       "      <td>Solicitor Contacts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:\\ML Training Docs\\New folder\\split\\Train\\MDU...</td>\n",
       "      <td>Solicitor Contacts</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           filenames              target\n",
       "0  C:\\ML Training Docs\\New folder\\split\\Train\\MDU...  Solicitor Contacts\n",
       "0  C:\\ML Training Docs\\New folder\\split\\Train\\MDU...  Solicitor Contacts"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df=pd.DataFrame({'filenames':[my_data.filenames],'target':[my_data.target]})\n",
    "df=explode(df,['filenames','target'],fill_value='',preserve_index=True)\n",
    "df['target']=df['target'].replace([0,1,2,3,4],['3rd Party Expert','GMC','Solicitor Contacts','MDU Invoices','NHSLA'])\n",
    "# df.to_csv(r'C:\\ML Training Docs\\New folder\\data_final\\data_final.csv',index=False)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f154142a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "documents = []\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "stemmer = WordNetLemmatizer()\n",
    "\n",
    "for sen in range(0, len(X)):\n",
    "    \n",
    "    #Remove \\n from text\n",
    "    document = re.sub(r'\\\\n', ' ', str(X[sen]))\n",
    "    \n",
    "    # remove \\t from text\n",
    "    document = re.sub(r'\\\\t', ' ', document)\n",
    "    \n",
    "     # Remove \\\\ from the text\n",
    "    document = re.sub(r'\\\\', ' ', document)\n",
    "    \n",
    "     # Removing prefixed 'b'\n",
    "    document = re.sub(r'^b\\s+', '', document)\n",
    "    \n",
    "    \n",
    "    #Remove special character\n",
    "    document = re.sub(r\"[^a-zA-Z0-9]+\", ' ', document)\n",
    "    \n",
    "   \n",
    "\n",
    "    \n",
    "    # Remove one char joins with 2 digit number\n",
    "    document= re.sub(r'[A-Za-z]{1}[0-9]{2}', ' ', document)\n",
    "    #Remove 1 digit number joins with 2 char\n",
    "    document = re.sub(r'[0-9]{1}[A-Za-z]{2}',' ',document)\n",
    "     #Remove one char in between two numbers\n",
    "    document = re.sub(r'[0-9]{1}[A-Za-z]{1}[0-9]{1}',' ',document)\n",
    "    #Remove one number in between two char\n",
    "    document = re.sub(r'[A-Za-z]{1}[0-9]{1}[A-Za-z]{1}',' ',document)\n",
    "    \n",
    "    # Remove two char joins with 2 digit number\n",
    "    document= re.sub(r'[A-Za-z]{2}[0-9]{2}', ' ', document)\n",
    "    \n",
    "    # Remove two char joins with 1 digit number\n",
    "    document= re.sub(r'[A-Za-z]{2}[0-9]{1}', ' ', document)\n",
    "    \n",
    "   \n",
    "    # Remove double digit number\n",
    "    document=re.sub('(\\\\b[0-9][0-9] \\\\b|\\\\b [0-9][0-9]\\\\b)', ' ', document).strip()\n",
    "    #Remove single character\n",
    "    document=re.sub('(\\\\b[A-Za-z] \\\\b|\\\\b [A-Za-z]\\\\b)', ' ', document).strip()\n",
    "    # Remove single digit number\n",
    "    document=re.sub('(\\\\b[0-9] \\\\b|\\\\b [0-9]\\\\b)', ' ', document).strip()\n",
    "\n",
    "    # Substituting multiple spaces with single space\n",
    "#     document = re.sub(r' +', ' ', document)\n",
    "\n",
    "    # Converting to Lowercase\n",
    "    document = document.lower()\n",
    "    \n",
    "    # Lemmatization\n",
    "    document = document.split()\n",
    "\n",
    "    document = [stemmer.lemmatize(word) for word in document]\n",
    "    document = ' '.join(document)\n",
    "#     document = ' '.join(e for e in document if e.isalnum())\n",
    "    document = ' '.join([w for w in document.split() if len(w)>1])\n",
    "    \n",
    "    \n",
    "    \n",
    "    documents.append(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e245ccb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_list = documents\n",
    "from nltk.corpus import stopwords\n",
    "stop_words=set(stopwords.words('english'))\n",
    "\n",
    "clean_document = [' '.join([b for b in a.split() if b not in stop_words]) for a in doc_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88f38d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unidecode\n",
    "accented=[]\n",
    "for i in range(0,len(clean_document)):\n",
    "    ach=unidecode.unidecode(clean_document[i])\n",
    "    accented.append(ach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6dd89d74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['young fiona pthl o0 o2 sent subject attachment phillips mark october 2011 ddu advisory fw mr pihl health review pihl claes report gdc sept doc dewhurst charles sent september 2011 phillips mark subject fw mr pihl health review one another complimentary one looking good harry stewart tmaiito harry stewart capsticks com sent september 2011 dewhurst charles cc nimi bruce subject mr pihl health review dear mr dewhurst please find attached psychiatric report dr gilvarry dated september 2011 received email today please note yet received enclosure report informed hard copy ha sent post aim provide copy enclosure soon arrives capsticks kind regard harry stewart paralegal dd 020 8780 4854 harrv stewart caosticks com www capsticks com laing buisson independent healthcare award 2011 winner legal adviser year intended recipient email entitled mr pihl health review please delete email information contained communication confidential may legally privileged intended solely use intended recipient others authorised receive received message error hereby notified disclosure copying distribution taking action reliance content information strictly prohibited may unlawful please note capsticks doe accept service proceeding email capsticks solicitor llp limited liability partnership registered england wale registered number 0360 authorised regulated solicitor regulation authority list member open inspection registered office st george road st george east wimbledon london online www capsticks com term partner used refer member capsticks solicitor llp employee disclaimer young fiona pthl o0 o2 sent subject attachment phillips mark october 2011 ddu advisory fw mr pihl health review pihl claes report gdc sept doc dewhurst charles sent september 2011 phillips mark subject fw mr pihl health review one another complimentary one looking good harry stewart tmaiito harry stewart capsticks com sent september 2011 dewhurst charles cc nimi bruce subject mr pihl health review dear mr dewhurst please find attached psychiatric report dr gilvarry dated september 2011 received email today please note yet received enclosure report informed hard copy ha sent post aim provide copy enclosure soon arrives capsticks kind regard harry stewart paralegal dd 020 8780 4854 harrv stewart caosticks com www capsticks com laing buisson independent healthcare award 2011 winner legal adviser year intended recipient email entitled mr pihl health review please delete email information contained communication confidential may legally privileged intended solely use intended recipient others authorised receive received message error hereby notified disclosure copying distribution taking action reliance content information strictly prohibited may unlawful please note capsticks doe accept service proceeding email capsticks solicitor llp limited liability partnership registered england wale registered number 0360 authorised regulated solicitor regulation authority list member open inspection registered office st george road st george east wimbledon london online www capsticks com term partner used refer member capsticks solicitor llp employee disclaimer consultant equivalent standing qualification footnote confirms message ha scanned virus please consider environment printing message email ha scanned messagelabs email security system information please visit http rw messagelabs com email']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accented[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70d4bfc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(max_features=1500, min_df=5, max_df=0.7)\n",
    "X = vectorizer.fit_transform(accented).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d15dfe5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidfconverter = TfidfTransformer()\n",
    "X = tfidfconverter.fit_transform(X).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d929ffd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.20,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9450151e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random_forest_training time: 1.167 s\n",
      "RandomForest: 0.8768472906403941\n",
      "[[78  1  0  0  6]\n",
      " [ 6 62  0  0  4]\n",
      " [ 5  9 61  2  7]\n",
      " [ 0  0  2 86  0]\n",
      " [ 3  1  4  0 69]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.92      0.88        85\n",
      "           1       0.85      0.86      0.86        72\n",
      "           2       0.91      0.73      0.81        84\n",
      "           3       0.98      0.98      0.98        88\n",
      "           4       0.80      0.90      0.85        77\n",
      "\n",
      "    accuracy                           0.88       406\n",
      "   macro avg       0.88      0.88      0.87       406\n",
      "weighted avg       0.88      0.88      0.88       406\n",
      "\n",
      "Accuracy score (training): 0.998\n",
      "Accuracy score (test): 0.877\n"
     ]
    }
   ],
   "source": [
    "'''training the data in RF model'''\n",
    "import time\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "classifier=RandomForestClassifier()\n",
    "start = time.time()\n",
    "classifier.fit(X_train,y_train)\n",
    "# the time would be round to 3 decimal in seconds\n",
    "end = time.time()\n",
    "print (\"Random_forest_training time:\", round(end-start, 3), \"s\")\n",
    "# t1=time.time()\n",
    "y_pred=classifier.predict(X_test)\n",
    "# print (\"predict time:\", round(end-t1, 3), \"s\")\n",
    "print('RandomForest:',accuracy_score(y_test,y_pred))\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(\"Accuracy score (training): {0:.3f}\".format(classifier.score(X_train, y_train)))\n",
    "print(\"Accuracy score (test): {0:.3f}\".format(classifier.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "da08a1b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient_Boost_training time: 95.535 s\n",
      "GradientBoostingClassifier: 0.8817733990147784\n",
      "[[74  2  1  0  8]\n",
      " [ 6 61  1  0  4]\n",
      " [ 6  4 68  2  4]\n",
      " [ 0  0  3 85  0]\n",
      " [ 4  0  3  0 70]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.87      0.85        85\n",
      "           1       0.91      0.85      0.88        72\n",
      "           2       0.89      0.81      0.85        84\n",
      "           3       0.98      0.97      0.97        88\n",
      "           4       0.81      0.91      0.86        77\n",
      "\n",
      "    accuracy                           0.88       406\n",
      "   macro avg       0.88      0.88      0.88       406\n",
      "weighted avg       0.88      0.88      0.88       406\n",
      "\n",
      "Accuracy score (training): 0.997\n",
      "Accuracy score (test): 0.882\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "classifier=GradientBoostingClassifier()\n",
    "start = time.time()\n",
    "classifier.fit(X_train,y_train)\n",
    "end = time.time()\n",
    "print (\"Gradient_Boost_training time:\", round(end-start, 3), \"s\")\n",
    "y_pred=classifier.predict(X_test)\n",
    "print('GradientBoostingClassifier:',accuracy_score(y_test,y_pred))\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(\"Accuracy score (training): {0:.3f}\".format(classifier.score(X_train, y_train)))\n",
    "print(\"Accuracy score (test): {0:.3f}\".format(classifier.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc2a14d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMClassifier: 0.8669950738916257\n",
      "[[77  2  1  0  5]\n",
      " [ 7 61  0  0  4]\n",
      " [ 6  7 64  2  5]\n",
      " [ 0  0  1 87  0]\n",
      " [ 6  1  7  0 63]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.91      0.85        85\n",
      "           1       0.86      0.85      0.85        72\n",
      "           2       0.88      0.76      0.82        84\n",
      "           3       0.98      0.99      0.98        88\n",
      "           4       0.82      0.82      0.82        77\n",
      "\n",
      "    accuracy                           0.87       406\n",
      "   macro avg       0.87      0.86      0.86       406\n",
      "weighted avg       0.87      0.87      0.87       406\n",
      "\n",
      "Accuracy score (training): 0.997\n",
      "Accuracy score (test): 0.882\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "model = LGBMClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred_lgbm = model.predict(X_test)\n",
    "print('LGBMClassifier:',accuracy_score(y_test,y_pred_lgbm))\n",
    "print(confusion_matrix(y_test,y_pred_lgbm))\n",
    "print(classification_report(y_test,y_pred_lgbm))\n",
    "print(\"Accuracy score (training): {0:.3f}\".format(classifier.score(X_train, y_train)))\n",
    "print(\"Accuracy score (test): {0:.3f}\".format(classifier.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27887a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
