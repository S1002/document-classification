{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "04635824-f4e9-4d2c-bc21-15c92a60a2f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#code for converting docx to txt\n",
    "import os\n",
    "import docx2txt\n",
    "f=os.listdir(r\"C:\\ML Training Docs\\New folder\\data\\adv\\Mdusol_invoices\\.docx\\\\\")\n",
    "n=os.listdir(r\"C:\\ML Training Docs\\New folder\\data\\adv\\Mdusol_invoices\\.docx\\\\\")\n",
    "name=[i[:-5] for i in n if i.endswith('.docx')]\n",
    "file=[i for i in f if i.endswith('docx')]\n",
    "for i,j in zip(file,name):\n",
    "    # Passing docx file to process function\n",
    "    text = docx2txt.process(r\"C:\\ML Training Docs\\New folder\\data\\adv\\Mdusol_invoices\\.docx\\%s\"%i)\n",
    "    with open(\"C:/ML Training Docs/New folder/data/adv/Mdusol_invoices/.docx/txt2/%s.txt\"%j, \"w\",encoding=\"utf-8\") as text_file:\n",
    "        print(text, file=text_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1940437f-3327-48c5-ba32-d9a96ded97c8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'C:/ML Training Docs/New folder/data/adv/Mdusol_invoices/.docx/docx2txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-68-b1bd6ca82b4b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;31m#extract text from the file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m     \u001b[0mcontent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtextract\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource_directory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprocess_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[1;31m# We create and open the new and we prepare to write the Binary Data which is represented by the wb - Write Binary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\textract\\parsers\\__init__.py\u001b[0m in \u001b[0;36mprocess\u001b[1;34m(filename, input_encoding, output_encoding, extension, **kwargs)\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfiletype_module\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mParser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_encoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_encoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\textract\\parsers\\utils.py\u001b[0m in \u001b[0;36mprocess\u001b[1;34m(self, filename, input_encoding, output_encoding, **kwargs)\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[1;31m# output encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[1;31m# http://nedbatchelder.com/text/unipain/unipain.html#35\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m         \u001b[0mbyte_string\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextract\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m         \u001b[0municode_string\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbyte_string\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_encoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0municode_string\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_encoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\textract\\parsers\\txt_parser.py\u001b[0m in \u001b[0;36mextract\u001b[1;34m(self, filename, **kwargs)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextract\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'C:/ML Training Docs/New folder/data/adv/Mdusol_invoices/.docx/docx2txt'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import uuid\n",
    "import textract\n",
    "\n",
    "# source_directory = 'E:/PPT/docx/'\n",
    "source_directory = os.path.join('C:/ML Training Docs/New folder/data/adv/Mdusol_invoices/.docx/')\n",
    "\n",
    "for filename in os.listdir(source_directory):\n",
    "    file, extension = os.path.splitext(filename)\n",
    "    unique_filename = str(uuid.uuid4()) + extension\n",
    "#     os.rename(os.path.join(source_directory,  filename), os.path.join(source_directory, unique_filename))\n",
    "\n",
    "# training_directory = 'E:/PPT/docx/'\n",
    "training_directory = os.path.join('C:/ML Training Docs/New folder/data/adv/Mdusol_invoices/.docx/txt1')\n",
    "\n",
    "for process_file in  os.listdir(source_directory):\n",
    "    file, extension = os.path.splitext(process_file)\n",
    "    \n",
    "    # We create a new text file name by concatenating the .txt extension to file UUID\n",
    "    dest_file_path = file + '.txt'\n",
    "    \n",
    "    #extract text from the file\n",
    "    content = textract.process(os.path.join(source_directory, process_file))\n",
    "    \n",
    "    # We create and open the new and we prepare to write the Binary Data which is represented by the wb - Write Binary\n",
    "    write_text_file = open(os.path.join(training_directory, dest_file_path), \"wb\")\n",
    "    \n",
    "    #write the content and close the newly created file\n",
    "    write_text_file.write(content)\n",
    "    write_text_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1aead079-8013-437a-ba12-f28cb1d66901",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "for filename in glob.glob(r'C:\\ML Training Docs\\New folder\\data\\adv\\3rdparties\\.xls\\*.xls'):\n",
    "    df=pd.read_excel(filename)\n",
    "    df.to_string('C:/ML Training Docs/New folder/data/adv/3rdparties/.xls/xls2txt/'+(filename.split('.')[-2]).split('\\\\')[-1]+'.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "bdfd570b-2464-45fd-8b7d-cb32d5957001",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:/ML Training Docs/New folder/data/adv/sol_contacts/.doc/doc2txt/110002.txt'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'C:/ML Training Docs/New folder/data/adv/sol_contacts/.doc/doc2txt/'+(docxFilename.split('.')[-2]).split('\\\\')[-1]+'.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9e0bbc24-fda6-4782-812f-5b8fd0f88969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\ML Training Docs\\New folder\\data\\adv\\regbody_gmc\\.doc\\1760008.doc\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Invalid input format! Got \"doc\" but expected one of these: biblatex, bibtex, commonmark, commonmark_x, creole, csljson, csv, docbook, docx, dokuwiki, epub, fb2, gfm, haddock, html, ipynb, jats, jira, json, latex, man, markdown, markdown_github, markdown_mmd, markdown_phpextra, markdown_strict, mediawiki, muse, native, odt, opml, org, rst, rtf, t2t, textile, tikiwiki, twiki, vimwiki",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-67-1068ebdc1abe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mdocxFilename\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'C:\\ML Training Docs\\New folder\\data\\adv\\regbody_gmc\\.doc\\*.doc'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdocxFilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0moutput\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpypandoc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdocxFilename\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'plain'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moutputfile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdocxFilename\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'.txt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[1;32massert\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pypandoc\\__init__.py\u001b[0m in \u001b[0;36mconvert_file\u001b[1;34m(source_file, to, format, extra_args, encoding, outputfile, filters, verify_format)\u001b[0m\n\u001b[0;32m    136\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"source_file is not a valid path\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m     \u001b[0mformat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_identify_format_from_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 138\u001b[1;33m     return _convert_input(source_file, format, 'path', to, extra_args=extra_args,\n\u001b[0m\u001b[0;32m    139\u001b[0m                           \u001b[0moutputfile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutputfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfilters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m                           verify_format=verify_format)\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pypandoc\\__init__.py\u001b[0m in \u001b[0;36m_convert_input\u001b[1;34m(source, format, input_type, to, extra_args, outputfile, filters, verify_format)\u001b[0m\n\u001b[0;32m    261\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mverify_format\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 263\u001b[1;33m         \u001b[0mformat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_validate_formats\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    264\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m         \u001b[0mformat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnormalize_format\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pypandoc\\__init__.py\u001b[0m in \u001b[0;36m_validate_formats\u001b[1;34m(format, to, outputfile)\u001b[0m\n\u001b[0;32m    219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_get_base_format\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfrom_formats\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 221\u001b[1;33m         raise RuntimeError(\n\u001b[0m\u001b[0;32m    222\u001b[0m             'Invalid input format! Got \"%s\" but expected one of these: %s' % (\n\u001b[0;32m    223\u001b[0m                 _get_base_format(format), ', '.join(from_formats)))\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Invalid input format! Got \"doc\" but expected one of these: biblatex, bibtex, commonmark, commonmark_x, creole, csljson, csv, docbook, docx, dokuwiki, epub, fb2, gfm, haddock, html, ipynb, jats, jira, json, latex, man, markdown, markdown_github, markdown_mmd, markdown_phpextra, markdown_strict, mediawiki, muse, native, odt, opml, org, rst, rtf, t2t, textile, tikiwiki, twiki, vimwiki"
     ]
    }
   ],
   "source": [
    "import pypandoc\n",
    "import glob\n",
    "for docxFilename in glob.glob(r'C:\\ML Training Docs\\New folder\\data\\adv\\regbody_gmc\\.doc\\*.doc'):\n",
    "    print(docxFilename)\n",
    "    output=pypandoc.convert_file(docxFilename,'plain',outputfile=docxFilename+'.txt')\n",
    "    assert output==''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "dd6417e5-12dd-450b-9a6a-a416120b7325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n"
     ]
    }
   ],
   "source": [
    "from PyPDF2 import PdfFileReader, PdfFileWriter\n",
    "import os\n",
    "\n",
    "path=r'C:/ML Training Docs/New folder/data/adv/3rdparties/.pdf/'\n",
    "des=r'C:/ML Training Docs/New folder/data/adv/3rdparties/.pdf/pdf_to_txt/'\n",
    "a=1\n",
    "for r, d, f in os.walk(path):\n",
    "    for file in f:\n",
    "        if '.pdf' in file:\n",
    "            file_path=(os.path.join(r, file))\n",
    "            try:\n",
    "                pdf = PdfFileReader(file_path,strict=False)\n",
    "                with open(os.path.join(des, (os.path.splitext(file)[0].lower())+'.txt'), 'w',encoding='utf-8') as f:\n",
    "                    for page_num in range(pdf.numPages):\n",
    "                        # print('Page: {0}'.format(page_num))\n",
    "                        pageObj = pdf.getPage(page_num)\n",
    "                        try:\n",
    "                            txt = pageObj.extractText()\n",
    "                        except:\n",
    "                            pass\n",
    "                        else:\n",
    "                            f.write(txt)\n",
    "                f.close()\n",
    "            except:\n",
    "                pass\n",
    "            print(a)\n",
    "            a=a+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34a4dd72-b580-4908-b4c8-32945cf09ab0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\ML Training Docs\\\\New folder\\\\data\\\\adv\\\\Mdusol_invoices\\\\.msg\\\\msg_to_txt\\\\pdf\\\\0195_001.pdf',\n",
       " 'C:\\\\ML Training Docs\\\\New folder\\\\data\\\\adv\\\\Mdusol_invoices\\\\.msg\\\\msg_to_txt\\\\pdf\\\\0548_001.pdf',\n",
       " 'C:\\\\ML Training Docs\\\\New folder\\\\data\\\\adv\\\\Mdusol_invoices\\\\.msg\\\\msg_to_txt\\\\pdf\\\\0658_001.pdf',\n",
       " 'C:\\\\ML Training Docs\\\\New folder\\\\data\\\\adv\\\\Mdusol_invoices\\\\.msg\\\\msg_to_txt\\\\pdf\\\\0673_001.pdf',\n",
       " 'C:\\\\ML Training Docs\\\\New folder\\\\data\\\\adv\\\\Mdusol_invoices\\\\.msg\\\\msg_to_txt\\\\pdf\\\\0918_001.pdf',\n",
       " 'C:\\\\ML Training Docs\\\\New folder\\\\data\\\\adv\\\\Mdusol_invoices\\\\.msg\\\\msg_to_txt\\\\pdf\\\\10227608.pdf',\n",
       " 'C:\\\\ML Training Docs\\\\New folder\\\\data\\\\adv\\\\Mdusol_invoices\\\\.msg\\\\msg_to_txt\\\\pdf\\\\1354443.pdf',\n",
       " 'C:\\\\ML Training Docs\\\\New folder\\\\data\\\\adv\\\\Mdusol_invoices\\\\.msg\\\\msg_to_txt\\\\pdf\\\\160505 Dr Thomas Murphy_3528805.PDF',\n",
       " 'C:\\\\ML Training Docs\\\\New folder\\\\data\\\\adv\\\\Mdusol_invoices\\\\.msg\\\\msg_to_txt\\\\pdf\\\\20120823 MDU Solicitor Contacts IN Hempsons  201208241316535578945.PDF',\n",
       " 'C:\\\\ML Training Docs\\\\New folder\\\\data\\\\adv\\\\Mdusol_invoices\\\\.msg\\\\msg_to_txt\\\\pdf\\\\20130501 MDU Solicitor Invoices IN EASTWOODS 201305101131427089642.PDF',\n",
       " 'C:\\\\ML Training Docs\\\\New folder\\\\data\\\\adv\\\\Mdusol_invoices\\\\.msg\\\\msg_to_txt\\\\pdf\\\\20131128 MDU Solicitor Invoices IN Kennedys Solicitors 201312061311152677435.PDF',\n",
       " 'C:\\\\ML Training Docs\\\\New folder\\\\data\\\\adv\\\\Mdusol_invoices\\\\.msg\\\\msg_to_txt\\\\pdf\\\\20160728 MDU Solicitor Invoices IN John Hayes Costs Lawyers 201612141020561437522.PDF',\n",
       " 'C:\\\\ML Training Docs\\\\New folder\\\\data\\\\adv\\\\Mdusol_invoices\\\\.msg\\\\msg_to_txt\\\\pdf\\\\20161018 MDU Solicitor Invoices in Smith A 201610190915094788140 Kader 1508500-00 me2571_201610181634.pdf',\n",
       " 'C:\\\\ML Training Docs\\\\New folder\\\\data\\\\adv\\\\Mdusol_invoices\\\\.msg\\\\msg_to_txt\\\\pdf\\\\20161018 MDU Solicitor Invoices in Smith A 201610190916584638865 Kader  1508500-00_201610181634.pdf',\n",
       " 'C:\\\\ML Training Docs\\\\New folder\\\\data\\\\adv\\\\Mdusol_invoices\\\\.msg\\\\msg_to_txt\\\\pdf\\\\20190827 Registration Body GDC in 201908271033470681497 GDC correspondence FAO Lucy Williams CAS-190266.pdf',\n",
       " 'C:\\\\ML Training Docs\\\\New folder\\\\data\\\\adv\\\\Mdusol_invoices\\\\.msg\\\\msg_to_txt\\\\pdf\\\\20190827 Registration Body GDC in 201908271033496889833 GDC SUMMARY OF ALLEGATIONS CAS-190266 LW.pdf',\n",
       " 'C:\\\\ML Training Docs\\\\New folder\\\\data\\\\adv\\\\Mdusol_invoices\\\\.msg\\\\msg_to_txt\\\\pdf\\\\2202181.pdf',\n",
       " 'C:\\\\ML Training Docs\\\\New folder\\\\data\\\\adv\\\\Mdusol_invoices\\\\.msg\\\\msg_to_txt\\\\pdf\\\\2735_001.pdf',\n",
       " 'C:\\\\ML Training Docs\\\\New folder\\\\data\\\\adv\\\\Mdusol_invoices\\\\.msg\\\\msg_to_txt\\\\pdf\\\\3364_001.pdf',\n",
       " 'C:\\\\ML Training Docs\\\\New folder\\\\data\\\\adv\\\\Mdusol_invoices\\\\.msg\\\\msg_to_txt\\\\pdf\\\\8160604.pdf',\n",
       " 'C:\\\\ML Training Docs\\\\New folder\\\\data\\\\adv\\\\Mdusol_invoices\\\\.msg\\\\msg_to_txt\\\\pdf\\\\8164565.pdf',\n",
       " 'C:\\\\ML Training Docs\\\\New folder\\\\data\\\\adv\\\\Mdusol_invoices\\\\.msg\\\\msg_to_txt\\\\pdf\\\\8164572.pdf',\n",
       " 'C:\\\\ML Training Docs\\\\New folder\\\\data\\\\adv\\\\Mdusol_invoices\\\\.msg\\\\msg_to_txt\\\\pdf\\\\8169911.pdf',\n",
       " 'C:\\\\ML Training Docs\\\\New folder\\\\data\\\\adv\\\\Mdusol_invoices\\\\.msg\\\\msg_to_txt\\\\pdf\\\\8176317.pdf',\n",
       " 'C:\\\\ML Training Docs\\\\New folder\\\\data\\\\adv\\\\Mdusol_invoices\\\\.msg\\\\msg_to_txt\\\\pdf\\\\AC#31014806.4.pdf',\n",
       " \"C:\\\\ML Training Docs\\\\New folder\\\\data\\\\adv\\\\Mdusol_invoices\\\\.msg\\\\msg_to_txt\\\\pdf\\\\Al Nageim - csl's fee note.pdf\",\n",
       " 'C:\\\\ML Training Docs\\\\New folder\\\\data\\\\adv\\\\Mdusol_invoices\\\\.msg\\\\msg_to_txt\\\\pdf\\\\Bali ticket.pdf',\n",
       " 'C:\\\\ML Training Docs\\\\New folder\\\\data\\\\adv\\\\Mdusol_invoices\\\\.msg\\\\msg_to_txt\\\\pdf\\\\Bill-4107278-20191007-WM-S03-NEW-20191007174157.pdf',\n",
       " 'C:\\\\ML Training Docs\\\\New folder\\\\data\\\\adv\\\\Mdusol_invoices\\\\.msg\\\\msg_to_txt\\\\pdf\\\\Byrne.pdf',\n",
       " 'C:\\\\ML Training Docs\\\\New folder\\\\data\\\\adv\\\\Mdusol_invoices\\\\.msg\\\\msg_to_txt\\\\pdf\\\\Counsel fee note 23.08.17.pdf',\n",
       " 'C:\\\\ML Training Docs\\\\New folder\\\\data\\\\adv\\\\Mdusol_invoices\\\\.msg\\\\msg_to_txt\\\\pdf\\\\Counsel_s updated fee note.PDF',\n",
       " 'C:\\\\ML Training Docs\\\\New folder\\\\data\\\\adv\\\\Mdusol_invoices\\\\.msg\\\\msg_to_txt\\\\pdf\\\\DAC Beachcroft invoice - 06.01.15.PDF',\n",
       " 'C:\\\\ML Training Docs\\\\New folder\\\\data\\\\adv\\\\Mdusol_invoices\\\\.msg\\\\msg_to_txt\\\\pdf\\\\DefenceÂ\\xa0IOCÂ\\xa0Bundle.pdf',\n",
       " 'C:\\\\ML Training Docs\\\\New folder\\\\data\\\\adv\\\\Mdusol_invoices\\\\.msg\\\\msg_to_txt\\\\pdf\\\\DOCRULE7RESPONSEBUNDLE.PDF',\n",
       " 'C:\\\\ML Training Docs\\\\New folder\\\\data\\\\adv\\\\Mdusol_invoices\\\\.msg\\\\msg_to_txt\\\\pdf\\\\DrCWilliamsRULE7RESPONSE.PDF',\n",
       " 'C:\\\\ML Training Docs\\\\New folder\\\\data\\\\adv\\\\Mdusol_invoices\\\\.msg\\\\msg_to_txt\\\\pdf\\\\Fee Note_11_4_2013_9_4_33_670.pdf',\n",
       " 'C:\\\\ML Training Docs\\\\New folder\\\\data\\\\adv\\\\Mdusol_invoices\\\\.msg\\\\msg_to_txt\\\\pdf\\\\Fee Note_11_4_2013_9_4_52_858.pdf',\n",
       " 'C:\\\\ML Training Docs\\\\New folder\\\\data\\\\adv\\\\Mdusol_invoices\\\\.msg\\\\msg_to_txt\\\\pdf\\\\Fee-note - Malcolm Fortune - 85584 (2).PDF',\n",
       " 'C:\\\\ML Training Docs\\\\New folder\\\\data\\\\adv\\\\Mdusol_invoices\\\\.msg\\\\msg_to_txt\\\\pdf\\\\Fynes 1200457-00.pdf',\n",
       " 'C:\\\\ML Training Docs\\\\New folder\\\\data\\\\adv\\\\Mdusol_invoices\\\\.msg\\\\msg_to_txt\\\\pdf\\\\gmc warnings guidance.pdf',\n",
       " 'C:\\\\ML Training Docs\\\\New folder\\\\data\\\\adv\\\\Mdusol_invoices\\\\.msg\\\\msg_to_txt\\\\pdf\\\\Hundle 1110832-00  .pdf',\n",
       " 'C:\\\\ML Training Docs\\\\New folder\\\\data\\\\adv\\\\Mdusol_invoices\\\\.msg\\\\msg_to_txt\\\\pdf\\\\InterimFee-V1.pdf',\n",
       " 'C:\\\\ML Training Docs\\\\New folder\\\\data\\\\adv\\\\Mdusol_invoices\\\\.msg\\\\msg_to_txt\\\\pdf\\\\InterimFee219020-V1.pdf',\n",
       " 'C:\\\\ML Training Docs\\\\New folder\\\\data\\\\adv\\\\Mdusol_invoices\\\\.msg\\\\msg_to_txt\\\\pdf\\\\INV284973 - Credit Note.pdf',\n",
       " 'C:\\\\ML Training Docs\\\\New folder\\\\data\\\\adv\\\\Mdusol_invoices\\\\.msg\\\\msg_to_txt\\\\pdf\\\\INV284973.pdf',\n",
       " 'C:\\\\ML Training Docs\\\\New folder\\\\data\\\\adv\\\\Mdusol_invoices\\\\.msg\\\\msg_to_txt\\\\pdf\\\\INV285244.pdf',\n",
       " 'C:\\\\ML Training Docs\\\\New folder\\\\data\\\\adv\\\\Mdusol_invoices\\\\.msg\\\\msg_to_txt\\\\pdf\\\\INV285264.pdf',\n",
       " 'C:\\\\ML Training Docs\\\\New folder\\\\data\\\\adv\\\\Mdusol_invoices\\\\.msg\\\\msg_to_txt\\\\pdf\\\\Invoice No. 06-12-0000411_1_MDUS01.PDF',\n",
       " 'C:\\\\ML Training Docs\\\\New folder\\\\data\\\\adv\\\\Mdusol_invoices\\\\.msg\\\\msg_to_txt\\\\pdf\\\\Invoice_1215072_Proforma_109318_2013.5.20[1].pdf',\n",
       " 'C:\\\\ML Training Docs\\\\New folder\\\\data\\\\adv\\\\Mdusol_invoices\\\\.msg\\\\msg_to_txt\\\\pdf\\\\Invoice_1230605_Proforma_149272_2014.4.16.pdf',\n",
       " 'C:\\\\ML Training Docs\\\\New folder\\\\data\\\\adv\\\\Mdusol_invoices\\\\.msg\\\\msg_to_txt\\\\pdf\\\\Invoice_1230685_Proforma_149168_2014.4.16.pdf',\n",
       " 'C:\\\\ML Training Docs\\\\New folder\\\\data\\\\adv\\\\Mdusol_invoices\\\\.msg\\\\msg_to_txt\\\\pdf\\\\Invoice_1272344_Proforma_262185_2016.7.18.pdf',\n",
       " 'C:\\\\ML Training Docs\\\\New folder\\\\data\\\\adv\\\\Mdusol_invoices\\\\.msg\\\\msg_to_txt\\\\pdf\\\\Invoice_1272425_Proforma_262089_2016.7.19.pdf',\n",
       " 'C:\\\\ML Training Docs\\\\New folder\\\\data\\\\adv\\\\Mdusol_invoices\\\\.msg\\\\msg_to_txt\\\\pdf\\\\Invoice_1282429_Proforma_286401_2017.1.13.pdf',\n",
       " 'C:\\\\ML Training Docs\\\\New folder\\\\data\\\\adv\\\\Mdusol_invoices\\\\.msg\\\\msg_to_txt\\\\pdf\\\\Invoice_1287595_Proforma_300153_2017.4.7.pdf',\n",
       " 'C:\\\\ML Training Docs\\\\New folder\\\\data\\\\adv\\\\Mdusol_invoices\\\\.msg\\\\msg_to_txt\\\\pdf\\\\Kleiber - DDU.pdf',\n",
       " 'C:\\\\ML Training Docs\\\\New folder\\\\data\\\\adv\\\\Mdusol_invoices\\\\.msg\\\\msg_to_txt\\\\pdf\\\\MDU L&B 05.04.19 (2).PDF',\n",
       " \"C:\\\\ML Training Docs\\\\New folder\\\\data\\\\adv\\\\Mdusol_invoices\\\\.msg\\\\msg_to_txt\\\\pdf\\\\Member's updated PDP.pdf\",\n",
       " \"C:\\\\ML Training Docs\\\\New folder\\\\data\\\\adv\\\\Mdusol_invoices\\\\.msg\\\\msg_to_txt\\\\pdf\\\\O'Brien - DDU.pdf\",\n",
       " 'C:\\\\ML Training Docs\\\\New folder\\\\data\\\\adv\\\\Mdusol_invoices\\\\.msg\\\\msg_to_txt\\\\pdf\\\\Receipts 1.pdf (2).PDF',\n",
       " 'C:\\\\ML Training Docs\\\\New folder\\\\data\\\\adv\\\\Mdusol_invoices\\\\.msg\\\\msg_to_txt\\\\pdf\\\\Romania ticket.pdf',\n",
       " 'C:\\\\ML Training Docs\\\\New folder\\\\data\\\\adv\\\\Mdusol_invoices\\\\.msg\\\\msg_to_txt\\\\pdf\\\\Scan-to-Me from mfdbrs33.bwlaw.co.uk 2015-01-15 160925.pdf',\n",
       " 'C:\\\\ML Training Docs\\\\New folder\\\\data\\\\adv\\\\Mdusol_invoices\\\\.msg\\\\msg_to_txt\\\\pdf\\\\Yeoh  1608913-00.pdf']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glob import glob\n",
    "root_path= r'C:\\ML Training Docs\\New folder\\data\\adv\\Mdusol_invoices\\.msg\\msg_to_txt\\pdf'\n",
    "\n",
    "directory = glob(f'{root_path}/**//*.pdf', recursive=True)\n",
    "directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df971535-bf1f-4c17-9730-d479ea7e0c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of pages: 2\n",
      "number of pages: 4\n",
      "number of pages: 5\n",
      "number of pages: 2\n",
      "number of pages: 7\n",
      "number of pages: 4\n",
      "number of pages: 6\n",
      "number of pages: 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mupdf: cannot find startxref\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of pages: 3\n",
      "number of pages: 5\n",
      "number of pages: 3\n",
      "number of pages: 2\n",
      "number of pages: 4\n",
      "number of pages: 6\n",
      "number of pages: 17\n",
      "number of pages: 6\n",
      "number of pages: 5\n",
      "number of pages: 4\n",
      "number of pages: 3\n",
      "number of pages: 4\n",
      "number of pages: 4\n",
      "number of pages: 5\n",
      "number of pages: 4\n",
      "number of pages: 5\n",
      "number of pages: 2\n",
      "number of pages: 1\n",
      "number of pages: 1\n",
      "number of pages: 5\n",
      "number of pages: 2\n",
      "number of pages: 1\n",
      "number of pages: 1\n",
      "number of pages: 2\n",
      "number of pages: 51\n",
      "number of pages: 53\n",
      "number of pages: 11\n",
      "number of pages: 1\n",
      "number of pages: 1\n",
      "number of pages: 1\n",
      "number of pages: 6\n",
      "number of pages: 5\n",
      "number of pages: 4\n",
      "number of pages: 5\n",
      "number of pages: 6\n",
      "number of pages: 2\n",
      "number of pages: 2\n",
      "number of pages: 2\n",
      "number of pages: 2\n",
      "number of pages: 6\n",
      "number of pages: 2\n",
      "number of pages: 6\n",
      "number of pages: 6\n",
      "number of pages: 2\n",
      "number of pages: 10\n",
      "number of pages: 2\n",
      "number of pages: 9\n",
      "number of pages: 7\n",
      "number of pages: 5\n",
      "number of pages: 7\n",
      "number of pages: 2\n",
      "number of pages: 7\n",
      "number of pages: 1\n",
      "number of pages: 2\n",
      "number of pages: 4\n"
     ]
    }
   ],
   "source": [
    "import fitz\n",
    "\n",
    "for j in directory:\n",
    "    pdf_document =j\n",
    "    name=j.split('\\\\')[-1]\n",
    "    doc = fitz.open(pdf_document)\n",
    "    n=doc.pageCount\n",
    "    print (\"number of pages: %i\" % n)\n",
    "#print(doc.metadata)\n",
    "\n",
    "    for i in range(n):\n",
    "\n",
    "        page1 = doc.loadPage(i)\n",
    "        page1text = page1.getText()\n",
    "        #print(page1text)\n",
    "        file1=open(r'C:\\ML Training Docs\\New folder\\data\\adv\\Mdusol_invoices\\.msg\\msg_to_txt\\pdf_to_txt\\%s.txt'%name,'a',encoding='utf-8')\n",
    "        file1.writelines(page1text)\n",
    "        file1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "231a3456-951e-4470-a6ed-8b44be4e2c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cc9b0f60-c915-48ce-8324-351f806d7de4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n"
     ]
    }
   ],
   "source": [
    "Pathname= r'C:\\ML Training Docs\\New folder\\data\\adv\\3rdparties\\.msg\\msg_to_txt'\n",
    "import win32com.client\n",
    "import os\n",
    "a=1\n",
    "p= r'C:\\ML Training Docs\\New folder\\data\\adv\\3rdparties\\.msg'\n",
    "files = [f for f in os.listdir('C:/ML Training Docs/New folder/data/3rdparties/.msg/')]\n",
    "for file in files:\n",
    "    if file.endswith(\".msg\"):\n",
    "        outlook = win32com.client.Dispatch(\"Outlook.Application\").GetNamespace(\"MAPI\")\n",
    "        msg = outlook.OpenSharedItem(os.path.join(p, file))        \n",
    "        att=msg.Attachments\n",
    "        print(a)\n",
    "        a=a+1\n",
    "        for i in att:\n",
    "            i.SaveAsFile(os.path.join(Pathname, i.FileName))#Saves the file with the attachment name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cab15c11-2976-4a61-9f90-f940bd42e5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "for filename in glob.glob(r'C:\\ML Training Docs\\New folder\\data\\adv\\3rdparties\\.xlsx\\*.xlsx'):\n",
    "    df=pd.read_excel(filename)\n",
    "    df.to_string('C:/ML Training Docs/New folder/data/adv/3rdparties/.xlsx/xlsx_to_txt/'+(filename.split('.')[-2]).split('\\\\')[-1]+'.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b367044e-f5a3-4189-b612-b96ca44449f2",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 2] The system cannot find the file specified: 'C:\\\\ML Training Docs\\\\New folder\\\\data\\\\adv\\\\Mdusol_invoices\\\\.msg\\\\msg_to_txt\\\\pdf\\\\.pdf\\\\'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-58-b076de5a7734>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mDIR\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mr'C:\\ML Training Docs\\New folder\\data\\adv\\Mdusol_invoices\\.msg\\msg_to_txt\\pdf'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDIR\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'\\\\'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'.pdf\\\\'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mlistTostring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mstr1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] The system cannot find the file specified: 'C:\\\\ML Training Docs\\\\New folder\\\\data\\\\adv\\\\Mdusol_invoices\\\\.msg\\\\msg_to_txt\\\\pdf\\\\.pdf\\\\'"
     ]
    }
   ],
   "source": [
    "#pdf to txt\n",
    "import fitz\n",
    "import glob, os\n",
    "DIR = r'C:\\ML Training Docs\\New folder\\data\\adv\\Mdusol_invoices\\.msg\\msg_to_txt\\pdf'\n",
    "os.chdir(DIR+'\\\\'+'.pdf\\\\')\n",
    "def listTostring(s):\n",
    "    str1=\"\"\n",
    "    for ele in s:\n",
    "        str1 += ele\n",
    "    return str1\n",
    "for file in glob.glob(\"*PDF\"):\n",
    "    print(file)\n",
    "    filename = os.path.splitext(file)\n",
    "    filename = filename[0]\n",
    "    pdfs=[]\n",
    "    \n",
    "    with fitz.open(file) as doc:\n",
    "        text = \"\"\n",
    "        for page in doc:\n",
    "            text += page.getText(text)\n",
    "            pdfs.append(text)\n",
    "            \n",
    "        textfile = open(DIR + '\\\\' + '.pdf' + '\\\\' + 'pdf\\\\' + filename + '.txt','w',encoding='utf-8')\n",
    "    pages = listTostring(pdfs)\n",
    "    textfile.write(pages)\n",
    "    textfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ae3f36e-3422-4d94-85ff-afaed1a5f98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "##doc to docx\n",
    "from glob import glob\n",
    "import re\n",
    "import os\n",
    "import win32com.client as win32\n",
    "from win32com.client import constants\n",
    "\n",
    "# Create list of paths to .doc files\n",
    "paths = glob(r'C:\\ML Training Docs\\New folder\\data\\adv\\3rdparties\\.msg\\msg_to_txt\\rtf\\*.rtf', recursive=True)\n",
    "\n",
    "def save_as_docx(path):\n",
    "    # Opening MS Word\n",
    "    word = win32.gencache.EnsureDispatch('Word.Application')\n",
    "    doc = word.Documents.Open(path)\n",
    "    doc.Activate ()\n",
    "\n",
    "    # Rename path with .docx\n",
    "    new_file_abs = os.path.abspath(path)\n",
    "    new_file_abs = re.sub(r'\\.\\w+$', '.docx', new_file_abs)\n",
    "\n",
    "    # Save and Close\n",
    "    word.ActiveDocument.SaveAs(\n",
    "        new_file_abs, FileFormat=constants.wdFormatXMLDocument\n",
    "    )\n",
    "    doc.Close(False)\n",
    "\n",
    "for path in paths:\n",
    "    save_as_docx(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ecf9fabe-8ae6-4ade-a652-3aec59dc1722",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Code for moving converted text file to another folder\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "source_dir = r'C:/ML Training Docs/New folder/data/adv/Mdusol_invoices/.msg/msg_to_txt/doc/'\n",
    "target_dir = r'C:/ML Training Docs/New folder/data/adv/Mdusol_invoices/.msg/msg_to_txt/doc2docx/'\n",
    "\n",
    "file_names = os.listdir(source_dir)\n",
    "\n",
    "for file_name in file_names:\n",
    "    if file_name[-4:] == 'docx':\n",
    "        shutil.move(os.path.join(source_dir, file_name), target_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "96f3353d-ace9-4327-8e68-3c528f7aaf89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import uuid\n",
    "import textract\n",
    "\n",
    "# source_directory = 'E:/PPT/docx/'\n",
    "source_directory = os.path.join('C:/ML Training Docs/New folder/data/adv/3rdparties/.msg/msg_to_txt/rtf_to_docx/')\n",
    "\n",
    "for filename in os.listdir(source_directory):\n",
    "    file, extension = os.path.splitext(filename)\n",
    "    unique_filename = str(uuid.uuid4()) + extension\n",
    "#     os.rename(os.path.join(source_directory,  filename), os.path.join(source_directory, unique_filename))\n",
    "\n",
    "# training_directory = 'E:/PPT/docx/'\n",
    "training_directory = os.path.join('C:/ML Training Docs/New folder/data/adv/3rdparties/.msg/msg_to_txt/rtf_to_txt/')\n",
    "\n",
    "for process_file in  os.listdir(source_directory):\n",
    "    file, extension = os.path.splitext(process_file)\n",
    "    \n",
    "    # We create a new text file name by concatenating the .txt extension to file UUID\n",
    "    dest_file_path = file + '.txt'\n",
    "    \n",
    "    #extract text from the file\n",
    "    content = textract.process(os.path.join(source_directory, process_file))\n",
    "    \n",
    "    # We create and open the new and we prepare to write the Binary Data which is represented by the wb - Write Binary\n",
    "    write_text_file = open(os.path.join(training_directory, dest_file_path), \"wb\")\n",
    "    \n",
    "    #write the content and close the newly created file\n",
    "    write_text_file.write(content)\n",
    "    write_text_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e51652-941a-48c6-97a7-d7da52733438",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Code for moving converted text file to another folder\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "source_dir = 'C:/ML Training Docs/New folder/data/adv/3rdparties/.dotx/'\n",
    "target_dir = 'C:/ML Training Docs/New folder/data/adv/3rdparties/.dotx/dotx2docx/'\n",
    "\n",
    "file_names = os.listdir(source_dir)\n",
    "\n",
    "for file_name in file_names:\n",
    "    if file_name[-4:] == 'docx':\n",
    "        shutil.move(os.path.join(source_dir, file_name), target_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17dc7e3-b548-441f-9fbd-f4a2bf417556",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "import win32com.client\n",
    "\n",
    "baseDir = r'C:\\ML Training Docs\\New folder\\data\\adv\\Mdusol_invoices\\.doc' # Starting directory for directory walk\n",
    "\n",
    "word = win32com.client.Dispatch(\"Word.application\")\n",
    "\n",
    "for dir_path, dirs, files in os.walk(baseDir):\n",
    "\tfor file_name in files:\n",
    "\t\tfile_path = os.path.join(dir_path, file_name)\n",
    "\t\tfile_name, file_extension = os.path.splitext(file_path)\n",
    "\t\tif file_extension.lower() == '.doc': # \n",
    "\t\t\tdocx_file = '{0}{1}'.format(file_path, 'x')\n",
    "\t\t\tif not os.path.isfile(docx_file): # Skip conversion where docx file already exists\n",
    "\t\t\t\tprint('Converting: {0}'.format(file_path))\n",
    "\t\t\t\ttry:\n",
    "\t\t\t\t\twordDoc = word.Documents.Open(file_path, False, False, False)\n",
    "\t\t\t\t\twordDoc.SaveAs2(docx_file, FileFormat = 16)\n",
    "\t\t\t\t\twordDoc.Close()\n",
    "\t\t\t\texcept Exception: \n",
    "\t\t\t\t\tprint('Failed to Convert: {0}'.format(file_path))\n",
    "\n",
    "word.Quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e008c4a-1126-44f4-a98b-d78c7500dc3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "for filename in glob.glob(r'C:\\ML Training Docs\\New folder\\data\\adv\\3rdparties\\.msg\\msg_to_txt\\xls\\*.xls'):\n",
    "    df=pd.read_excel(filename)\n",
    "    df.to_string('C:/ML Training Docs/New folder/data/adv/3rdparties/.msg/msg_to_txt/xls_to_txt/'+(filename.split('.')[-2]).split('\\\\')[-1]+'.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b647685c-bb94-40e1-a85a-94094b81da8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
