{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3dbad96",
   "metadata": {},
   "source": [
    "# Document classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "241beda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "#nltk.download('stopwords')\n",
    "import pickle\n",
    "#from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e94e2671",
   "metadata": {},
   "outputs": [],
   "source": [
    "def explode(df, lst_cols, fill_value='', preserve_index=False):\n",
    "    # make sure `lst_cols` is list-alike\n",
    "    if (lst_cols is not None\n",
    "        and len(lst_cols) > 0\n",
    "        and not isinstance(lst_cols, (list, tuple, np.ndarray, pd.Series))):\n",
    "        lst_cols = [lst_cols]\n",
    "    # all columns except `lst_cols`\n",
    "    idx_cols = df.columns.difference(lst_cols)\n",
    "    # calculate lengths of lists\n",
    "    lens = df[lst_cols[0]].str.len()\n",
    "    # preserve original index values    \n",
    "    idx = np.repeat(df.index.values, lens)\n",
    "    # create \"exploded\" DF\n",
    "    res = (pd.DataFrame({\n",
    "                col:np.repeat(df[col].values, lens)\n",
    "                for col in idx_cols},\n",
    "                index=idx)\n",
    "             .assign(**{col:np.concatenate(df.loc[lens>0, col].values)\n",
    "                            for col in lst_cols}))\n",
    "    # append those rows that have empty lists\n",
    "    if (lens == 0).any():\n",
    "        # at least one list in cells is empty\n",
    "        res = (res.append(df.loc[lens==0, idx_cols], sort=False)\n",
    "                  .fillna(fill_value))\n",
    "    # revert the original index order\n",
    "    res = res.sort_index()\n",
    "    # reset index if requested\n",
    "    if not preserve_index:        \n",
    "        res = res.reset_index(drop=True)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39427e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_files\n",
    "my_data=load_files(r'C:\\ML Training Docs\\New folder\\data_final')\n",
    "X,y = my_data.data, my_data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e342720d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filenames</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:\\ML Training Docs\\New folder\\data_final\\MDU ...</td>\n",
       "      <td>MDU Invoices</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:\\ML Training Docs\\New folder\\data_final\\MDU_...</td>\n",
       "      <td>Solicitor Contacts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:\\ML Training Docs\\New folder\\data_final\\NHSL...</td>\n",
       "      <td>NHSLA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:\\ML Training Docs\\New folder\\data_final\\3rd ...</td>\n",
       "      <td>3rd Party Expert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:\\ML Training Docs\\New folder\\data_final\\MDU ...</td>\n",
       "      <td>MDU Invoices</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:\\ML Training Docs\\New folder\\data_final\\GMC\\...</td>\n",
       "      <td>GMC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:\\ML Training Docs\\New folder\\data_final\\GMC\\...</td>\n",
       "      <td>GMC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:\\ML Training Docs\\New folder\\data_final\\MDU ...</td>\n",
       "      <td>MDU Invoices</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:\\ML Training Docs\\New folder\\data_final\\NHSL...</td>\n",
       "      <td>NHSLA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:\\ML Training Docs\\New folder\\data_final\\NHSL...</td>\n",
       "      <td>NHSLA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2974 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filenames              target\n",
       "0   C:\\ML Training Docs\\New folder\\data_final\\MDU ...        MDU Invoices\n",
       "0   C:\\ML Training Docs\\New folder\\data_final\\MDU_...  Solicitor Contacts\n",
       "0   C:\\ML Training Docs\\New folder\\data_final\\NHSL...               NHSLA\n",
       "0   C:\\ML Training Docs\\New folder\\data_final\\3rd ...    3rd Party Expert\n",
       "0   C:\\ML Training Docs\\New folder\\data_final\\MDU ...        MDU Invoices\n",
       "..                                                ...                 ...\n",
       "0   C:\\ML Training Docs\\New folder\\data_final\\GMC\\...                 GMC\n",
       "0   C:\\ML Training Docs\\New folder\\data_final\\GMC\\...                 GMC\n",
       "0   C:\\ML Training Docs\\New folder\\data_final\\MDU ...        MDU Invoices\n",
       "0   C:\\ML Training Docs\\New folder\\data_final\\NHSL...               NHSLA\n",
       "0   C:\\ML Training Docs\\New folder\\data_final\\NHSL...               NHSLA\n",
       "\n",
       "[2974 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df=pd.DataFrame({'filenames':[my_data.filenames],'target':[my_data.target]})\n",
    "df=explode(df,['filenames','target'],fill_value='',preserve_index=True)\n",
    "df['target']=df['target'].replace([0,1,2,3,4],['3rd Party Expert','GMC','MDU Invoices','Solicitor Contacts','NHSLA'])\n",
    "df.to_csv(r'C:\\ML Training Docs\\New folder\\data_final\\data_final.csv',index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31025f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_csv(r'C:\\ML Training Docs\\New folder\\data1\\my_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a469a28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train=data.iloc[:,:1]\n",
    "# y_train=data.iloc[:,-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14e28201",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\zz2839\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "documents = []\n",
    "nltk.set_proxy('http://Boopathi.Murugesan:Welcometothemdu2021@proxy.mdu.local:8080')\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "stemmer = WordNetLemmatizer()\n",
    "\n",
    "for sen in range(0, len(X)):\n",
    "    # Remove all the special characters\n",
    "    document = re.sub(r'\\W', ' ', str(X[sen]))\n",
    "    \n",
    "    # remove all single characters\n",
    "    document = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', document)\n",
    "    \n",
    "    # Remove single characters from the start\n",
    "    document = re.sub(r'\\^[a-zA-Z]\\s+', ' ', document) \n",
    "    \n",
    "    # Substituting multiple spaces with single space\n",
    "    document = re.sub(r'\\s+', ' ', document, flags=re.I)\n",
    "    \n",
    "    # Removing prefixed 'b'\n",
    "    document = re.sub(r'^b\\s+', '', document)\n",
    "    \n",
    "    # Converting to Lowercase\n",
    "    document = document.lower()\n",
    "    \n",
    "    # Lemmatization\n",
    "    document = document.split()\n",
    "\n",
    "    document = [stemmer.lemmatize(word) for word in document]\n",
    "    document = ' '.join(document)\n",
    "    \n",
    "    documents.append(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "230b5043",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(max_features=1500, min_df=5, max_df=0.7)\n",
    "X = vectorizer.fit_transform(documents).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dabbe717",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidfconverter = TfidfTransformer()\n",
    "X = tfidfconverter.fit_transform(X).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba3ec9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.20,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ad1709e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8302521008403362\n"
     ]
    }
   ],
   "source": [
    "'''training the data in RF model'''\n",
    "from sklearn.ensemble._forest import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "classifier=RandomForestClassifier()\n",
    "classifier.fit(X_train,y_train)\n",
    "y_pred=classifier.predict(X_test)\n",
    "print(accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "671a10e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7445378151260504\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "classifier=MultinomialNB()\n",
    "classifier.fit(X_train,y_train)\n",
    "y_pred=classifier.predict(X_test)\n",
    "print(accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc42a954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[122  15   4   0   0]\n",
      " [ 25 138   3   3   2]\n",
      " [  8  18  41   4   1]\n",
      " [  1   0   7 121   0]\n",
      " [ 17  35   4   5  21]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.87      0.78       141\n",
      "           1       0.67      0.81      0.73       171\n",
      "           2       0.69      0.57      0.63        72\n",
      "           3       0.91      0.94      0.92       129\n",
      "           4       0.88      0.26      0.40        82\n",
      "\n",
      "    accuracy                           0.74       595\n",
      "   macro avg       0.77      0.69      0.69       595\n",
      "weighted avg       0.76      0.74      0.73       595\n",
      "\n",
      "0.7445378151260504\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02cd9d33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7260504201680672\n",
      "[[100  19  10   1  11]\n",
      " [ 18 136   7   2   8]\n",
      " [  7  10  41   5   9]\n",
      " [  4   1   7 116   1]\n",
      " [ 13  11  19   0  39]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.71      0.71       141\n",
      "           1       0.77      0.80      0.78       171\n",
      "           2       0.49      0.57      0.53        72\n",
      "           3       0.94      0.90      0.92       129\n",
      "           4       0.57      0.48      0.52        82\n",
      "\n",
      "    accuracy                           0.73       595\n",
      "   macro avg       0.69      0.69      0.69       595\n",
      "weighted avg       0.73      0.73      0.73       595\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "classifier=DecisionTreeClassifier()\n",
    "classifier.fit(X_train,y_train)\n",
    "y_pred=classifier.predict(X_test)\n",
    "print(accuracy_score(y_test,y_pred))\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d053dee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6773109243697479\n",
      "[[105   9   7   4  16]\n",
      " [ 24 103  21   5  18]\n",
      " [  5   8  40   6  13]\n",
      " [  4   1  16 107   1]\n",
      " [ 13  10   8   3  48]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.74      0.72       141\n",
      "           1       0.79      0.60      0.68       171\n",
      "           2       0.43      0.56      0.49        72\n",
      "           3       0.86      0.83      0.84       129\n",
      "           4       0.50      0.59      0.54        82\n",
      "\n",
      "    accuracy                           0.68       595\n",
      "   macro avg       0.65      0.66      0.65       595\n",
      "weighted avg       0.70      0.68      0.68       595\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "classifier=GaussianNB()\n",
    "classifier.fit(X_train,y_train)\n",
    "y_pred=classifier.predict(X_test)\n",
    "print(accuracy_score(y_test,y_pred))\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "158b8d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC: 0.8369747899159664\n",
      "[[125   7   6   0   3]\n",
      " [ 16 149   4   0   2]\n",
      " [  6  11  50   2   3]\n",
      " [  2   0   7 120   0]\n",
      " [ 15  10   2   1  54]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.89      0.82       141\n",
      "           1       0.84      0.87      0.86       171\n",
      "           2       0.72      0.69      0.71        72\n",
      "           3       0.98      0.93      0.95       129\n",
      "           4       0.87      0.66      0.75        82\n",
      "\n",
      "    accuracy                           0.84       595\n",
      "   macro avg       0.84      0.81      0.82       595\n",
      "weighted avg       0.84      0.84      0.84       595\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "classifier=SVC()\n",
    "classifier.fit(X_train,y_train)\n",
    "y_pred=classifier.predict(X_test)\n",
    "print('SVC:',accuracy_score(y_test,y_pred))\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cfd3a9a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression: 0.826890756302521\n",
      "[[123   8   6   0   4]\n",
      " [ 14 149   3   1   4]\n",
      " [  5  16  47   1   3]\n",
      " [  1   0   7 121   0]\n",
      " [ 13  13   3   1  52]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.87      0.83       141\n",
      "           1       0.80      0.87      0.83       171\n",
      "           2       0.71      0.65      0.68        72\n",
      "           3       0.98      0.94      0.96       129\n",
      "           4       0.83      0.63      0.72        82\n",
      "\n",
      "    accuracy                           0.83       595\n",
      "   macro avg       0.82      0.79      0.80       595\n",
      "weighted avg       0.83      0.83      0.82       595\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "classifier=LogisticRegression()\n",
    "classifier.fit(X_train,y_train)\n",
    "y_pred=classifier.predict(X_test)\n",
    "print('LogisticRegression:',accuracy_score(y_test,y_pred))\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "78c95a0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsclassifier: 0.7277310924369748\n",
      "[[115  17   0   1   8]\n",
      " [ 25 137   0   0   9]\n",
      " [ 24  15  24   1   8]\n",
      " [  5   1   2 120   1]\n",
      " [ 27  16   0   2  37]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.82      0.68       141\n",
      "           1       0.74      0.80      0.77       171\n",
      "           2       0.92      0.33      0.49        72\n",
      "           3       0.97      0.93      0.95       129\n",
      "           4       0.59      0.45      0.51        82\n",
      "\n",
      "    accuracy                           0.73       595\n",
      "   macro avg       0.76      0.67      0.68       595\n",
      "weighted avg       0.75      0.73      0.72       595\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "classifier=KNeighborsClassifier()\n",
    "classifier.fit(X_train,y_train)\n",
    "y_pred=classifier.predict(X_test)\n",
    "print('KNeighborsclassifier:',accuracy_score(y_test,y_pred))\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a29bbe5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifier: 0.8285714285714286\n",
      "[[116   6   8   0  11]\n",
      " [  9 146   6   2   8]\n",
      " [  6   7  50   4   5]\n",
      " [  1   0   3 124   1]\n",
      " [ 11   9   4   1  57]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82       141\n",
      "           1       0.87      0.85      0.86       171\n",
      "           2       0.70      0.69      0.70        72\n",
      "           3       0.95      0.96      0.95       129\n",
      "           4       0.70      0.70      0.70        82\n",
      "\n",
      "    accuracy                           0.83       595\n",
      "   macro avg       0.81      0.81      0.81       595\n",
      "weighted avg       0.83      0.83      0.83       595\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "classifier=SGDClassifier()\n",
    "classifier.fit(X_train,y_train)\n",
    "y_pred=classifier.predict(X_test)\n",
    "print('SGDClassifier:',accuracy_score(y_test,y_pred))\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc9e582",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
